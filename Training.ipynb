{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRERIAS A USAR PARA EL EMTRENAMIENTO\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Activation\n",
    "from tensorflow.python.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCIÓN QUE GUARDA EL MODELO DE LA RED NEURONAL\n",
    "def modelo():\n",
    "    vgg = applications.vgg16.VGG16() #Cargamos un modelo con capas ocultas para predecir imagenes\n",
    "    cnn = Sequential() #Creamos una pila lineal de capas de tipo sequencial\n",
    "    for capa in vgg.layers:\n",
    "        cnn.add(capa) #Agregamos todos las capas ocultas de vgg a cnn\n",
    "    cnn.layers.pop() #Quitamos el último elemento de cnn (con 1000 clases precargadas)\n",
    "    for layer in cnn.layers:\n",
    "        layer.trainable = False #Hacemos que el contenido de cnn no sea entrenable\n",
    "    cnn.add(Dense(2, activation = 'softmax')) #Agregamos la capa que vamos a usar para la predicción con el número de clases que hay\n",
    "    \n",
    "    return cnn #Regresamos el modelos con las capas preecargadas y la capa de predicción que creamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lectura de las directorios completa\n",
      "\n",
      "Found 2637 images belonging to 2 classes.\n",
      "Found 660 images belonging to 2 classes.\n",
      "\n",
      "Lectura de imagenes completa\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\Anaconda3\\envs\\rna\\lib\\site-packages\\ipykernel_launcher.py:45: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "K.clear_session() #Función de envoltura para limpiar después de las pruebas de TensorFlow\n",
    "\n",
    "#INGRESA LOS DATOS DE VALIDACIÓN Y ENTRENAMIENTO\n",
    "data_train = './data/train' #Carpeta de datos de entrenamiento\n",
    "data_test = './data/test' #Carpeta de datos de validación\n",
    "\n",
    "print(\"\\nLectura de las directorios completa\\n\")\n",
    "\n",
    "#VARIABLES DE ENTRENAMIENTO Y VALIDACIÓN\n",
    "epocas = 20 #Veces que va a entrenar el modelo\n",
    "longitud, altura = 224, 224 #Longitud que las imagenes van a tomar para el entrenamiento\n",
    "batch_size = 32 #Tamaño del lote fijo para las entradas\n",
    "pasos = 1000 #Número de pasos que va a realizar el modelo\n",
    "test_steps = 300 #Número de pasos que va a realizar en la validación\n",
    "lr = 0.0004 #Tasa de aprendizaje\n",
    "\n",
    "#PREPARAMOS LAS IMAGENES\n",
    "#Reescalamiento para las imagenes de entrenamiento a una escala de 255 y configura para que pueda leer tanto imagenes en zoom como volteadas\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1. / 255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True) \n",
    "\n",
    "#Reescala para las imagenes de prueba a una escala de 255\n",
    "test_datagen = ImageDataGenerator(rescale = 1. / 255) \n",
    "\n",
    "#Generamos las imagenes de entrenamiento\n",
    "train_generador = train_datagen.flow_from_directory(\n",
    "    data_train, \n",
    "    target_size = (altura, longitud), \n",
    "    batch_size = batch_size, \n",
    "    class_mode = 'categorical') \n",
    "\n",
    "#Generamos las imagenes de validación\n",
    "test_generador = test_datagen.flow_from_directory(\n",
    "    data_test, \n",
    "    target_size = (altura, longitud), \n",
    "    batch_size = batch_size, \n",
    "    class_mode = 'categorical') \n",
    "\n",
    "print(\"\\nLectura de imagenes completa\\n\")\n",
    "\n",
    "#CREA LA RED NEURONAL VGG16\n",
    "tic = time.clock() #Tiempo de inicio del entrenamiento\n",
    "\n",
    "cnn = modelo() #Cargamos el modelo de red neuronal convolucional (VGG16)\n",
    "\n",
    "#Configuramos el proceso de aprendizaje\n",
    "cnn.compile(\n",
    "    loss = 'categorical_crossentropy', #Función de pérdida\n",
    "    optimizers = optimizers.Adam(lr = lr), #Cadena del optimizador\n",
    "    metrics = ['accuracy']) #Lista de métricas por presición\n",
    "\n",
    "#ENTRENAMOS EL MODELO\n",
    "history = cnn.fit_generator(\n",
    "    train_generador, #Data a entrenar\n",
    "    steps_per_epoch = pasos, #Pasos a dar en la eopca\n",
    "    epochs = epocas, #Epocas del entrenamiento\n",
    "    validation_data = test_generador, #Data de validación\n",
    "    validation_steps = test_steps) #Pasos de validación\n",
    "\n",
    "toc = time.clock() #Tiempo de finalización del entrenamiento\n",
    "print('\\n')\n",
    "print(history.history.keys())\n",
    "\n",
    "#TIEMPO DE ENTRENAMIENTO\n",
    "time = toc - tic #Tiempo total del entrenamiento en segundos\n",
    "days = abs(time/86400) #Obiene los dias que tardo el entrenamiento\n",
    "ts1 = time - (days*86400) #Resta el tiempo en segundos y los dias convertidos en segundos\n",
    "hours = abs(ts1/3600) #Obtiene las horas que duro el entrenamiento\n",
    "ts2 = ts1 - (hours*3600) #Resta el restante en segundos y las horas convertidas en segundos\n",
    "minutes = abs(ts2/60) #Obtiene los minutos que duro el entrenamiento de acuerdo al sobrante de las horas\n",
    "ts3 = ts2 - (minutes*60) #Resta el sobrante en segundos y los minutos convertidas en segundos\n",
    "seconds = abs(ts3/60) #Obtiene los segundos del sobrante\n",
    "print(\"\\nEntrenamiento completo\")\n",
    "print(\"Tiempo de entrenamiento: \"+str(days)+\" días, \"+str(hours)+\" hrs, \"+str(minutes)+\" mins, \"+str(seconds)+\" sec\\n\")\n",
    "\n",
    "acc = history.evaluate(train_generator, test_generator, verbose = 1) #Porcentaje de presición\n",
    "err = 1 - acc #Porcentaje de presición\n",
    "print(\"\\nPorcentaje de presición: \"+str(acc*100)+\" %\")\n",
    "print(\"\\nPorcentaje de error: \"+str(err)+\" %\")\n",
    "      \n",
    "#GENERAMOS UN ARCHIVO QUE GUARDA EL MODELO Y LOS PESOS DEL MISMO\n",
    "target_dir = '.modelos/' #Dirección de la carpeta que guardará el modelo\n",
    "if not os.path.exists(target_dir): #Si la carpeta en la variable target_dir existe\n",
    "    os.mkdir(target_dir) #Genera la carpeta que guarda el modelo con la dirección de la variable target_dir\n",
    "cnn.save('.modelos/modelo.h5') #Genera un archivo con el modelo entrenado\n",
    "cnn.save_weights('.modelos/pesos.h5') #Genera un archivo con los pesos del modelo\n",
    "\n",
    "print(\"Archivos del modelo generados\\n\")\n",
    "\n",
    "#GRÁFICA DE PRESICIÓN EN EL ENTRENAMENIENTO / PRUEBA\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Precisión del modelo')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlabel('Epocas')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#GRÁFICA DE PRESICIÓN Y PÉRDIDA EN EL ENTRENAMENIENTO / PRUEBA\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Pérdida del modelo')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.xlabel('Epocas')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}